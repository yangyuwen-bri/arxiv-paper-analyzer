import streamlit as st
# å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(
    page_title="AIæ–°çŸ¥åº“",
    page_icon="ğŸ”¬",
    layout="wide"
)

import sys
import os
import webbrowser
from typing import Dict
from langchain_community.document_loaders import PyMuPDFLoader
import arxiv
from datetime import datetime

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ Python è·¯å¾„ä¸­
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from arxiv_analyzer import ArxivPaperAnalyzer
from document_processor import (
    AnalysisType, 
    DocumentProcessor,
)

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'analyzer' not in st.session_state:
        # ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–
        st.session_state.analyzer = ArxivPaperAnalyzer(
            model_type="openai",
            pdf_dir="custom_download_folder"  # æ­£ç¡®å‚æ•°ä½ç½®
        )
    if 'papers' not in st.session_state:
        st.session_state.papers = []
    if 'analyses' not in st.session_state:
        st.session_state.analyses = []
    if 'output_files' not in st.session_state:
        st.session_state.output_files = {}
    if 'doc_processor' not in st.session_state:
        st.session_state.doc_processor = DocumentProcessor()
    if 'micro_innovations' not in st.session_state:
        st.session_state.micro_innovations = {}  # ç»“æ„ï¼š{arxiv_id: analysis_text}

def sidebar_model_selection():
    """ä¾§è¾¹æ æ¨¡å‹é€‰æ‹©"""
    st.sidebar.header("ğŸ¤– æ¨¡å‹é€‰æ‹©")
    model_info = st.sidebar.radio(
        label="é€‰æ‹©æ¨¡å‹ç±»å‹",  
        options=["OpenAI", "DeepSeek"],
        index=0,
        horizontal=True,
        label_visibility="collapsed"
    )
    
    return {
        "model_type": "openai" if model_info == "OpenAI" else "deepseek"
    }

def load_arxiv_taxonomy():
    """åŠ è½½ArXivé¢†åŸŸåˆ†ç±»"""
    import pandas as pd
    
    try:
        df = pd.read_excel("arxiv_taxonomy_cn.xlsx")
        # æ„å»ºå±‚çº§å­—å…¸
        taxonomy = {}
        for _, row in df.iterrows():
            if row['Group'] not in taxonomy:
                taxonomy[row['Group']] = {}
            if pd.notna(row['Subgroup']):  # ç¡®ä¿Subgroupä¸æ˜¯NaN
                if row['Subgroup'] not in taxonomy[row['Group']]:
                    taxonomy[row['Group']][row['Subgroup']] = []
                taxonomy[row['Group']][row['Subgroup']].append({
                    'code': row['Code'],
                    'description': row['Description'] if pd.notna(row['Description']) else '',
                    'keywords': row['Keywords'] if pd.notna(row['Keywords']) else ''
                })
        return taxonomy
    except Exception as e:
        st.error(f"åŠ è½½é¢†åŸŸåˆ†ç±»å¤±è´¥: {str(e)}")
        return {}

def sidebar_search_options():
    """ä¾§è¾¹æ æœç´¢é€‰é¡¹"""
    st.sidebar.header("ğŸ” æœç´¢é€‰é¡¹")
    
    # é¢†åŸŸé€‰æ‹©
    field_method = st.sidebar.radio(
        "ç ”ç©¶é¢†åŸŸ",
        ["è‡ªåŠ¨æ¨è", "æ‰‹åŠ¨é€‰æ‹©"],
        index=0,
        horizontal=True
    )
    
    field = None
    if field_method == "æ‰‹åŠ¨é€‰æ‹©":
        # åŠ è½½é¢†åŸŸåˆ†ç±»
        taxonomy = load_arxiv_taxonomy()
        
        # ä¸»é¢†åŸŸé€‰æ‹©
        main_field = st.sidebar.selectbox(
            "ä¸»è¦é¢†åŸŸ",
            options=list(taxonomy.keys()),
            help="é€‰æ‹©è®ºæ–‡çš„ä¸»è¦ç ”ç©¶é¢†åŸŸ"
        )
        
        # å¦‚æœé€‰æ‹©äº†ä¸»é¢†åŸŸï¼Œæ˜¾ç¤ºå¯¹åº”çš„å­é¢†åŸŸé€‰æ‹©
        if main_field and main_field in taxonomy:
            sub_fields = list(taxonomy[main_field].keys())
            sub_field = st.sidebar.selectbox(
                "å­é¢†åŸŸ",
                options=sub_fields
            )
            if sub_field:
                field = [item['code'] for item in taxonomy[main_field][sub_field]]
    
    # å…¶ä»–æœç´¢é€‰é¡¹ï¼ˆåˆ é™¤åˆ†éš”çº¿ï¼‰
    max_papers = st.sidebar.slider(
        "è®ºæ–‡æ•°é‡",
        min_value=1,
        max_value=100,
        value=5
    )
    analysis_type = st.sidebar.radio(
        "åˆ†ææ·±åº¦", 
        ["æ‘˜è¦åˆ†æ", "å…¨æ–‡åˆ†æ"],
        index=0,
        horizontal=True
    )
    
    return {
        "field": field,
        "max_papers": max_papers,
        "analysis_type": analysis_type == "å…¨æ–‡åˆ†æ"
    }

def search_papers(model_type: str, search_options: Dict):
    """æœç´¢è®ºæ–‡"""
    st.session_state.analyzer = ArxivPaperAnalyzer(
        model_type=model_type,
        pdf_dir="custom_download_folder"
    )
    
    with st.spinner("æ­£åœ¨æœç´¢å’Œåˆ†æè®ºæ–‡..."):
        query = st.text_input(
            label="è®ºæ–‡æœç´¢",
            placeholder="è¾“å…¥ç ”ç©¶ä¸»é¢˜ï¼Œå¦‚ï¼šæœºå™¨å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†",
            label_visibility="collapsed"
        )
        
        if st.button("å¼€å§‹æœç´¢"):
            try:
                results = st.session_state.analyzer.search_and_analyze_papers(
                    query=query,
                    max_papers=search_options['max_papers'],
                    analyze_full_text=search_options['analysis_type'],
                    field=search_options['field']
                )
                
                st.session_state.papers = results.get('papers', [])
                # å°†å¾®åˆ›æ–°ç»“æœå­˜å…¥ç‹¬ç«‹å­˜å‚¨
                for paper in st.session_state.papers:
                    if 'micro_innovation' in paper:
                        paper_id = paper.get('arxiv_id')
                        if paper_id:
                            st.session_state.micro_innovations[paper_id] = paper['micro_innovation']
                
                st.session_state.analyses = results.get('analyses', [])
                st.session_state.output_files = results.get('outputs', {})
                st.session_state.doc_processor = results.get('doc_processor', DocumentProcessor())
                
                st.success(f"æˆåŠŸè·å– {len(st.session_state.papers)} ç¯‡è®ºæ–‡")
            except Exception as e:
                st.error(f"æœç´¢å¤±è´¥: {str(e)}")

def display_papers():
    st.markdown("""
    <style>
    .innovation-concept {
        font-size: 1.3em;
        color: #2c3e50;
        border-left: 4px solid #3498db;
        padding-left: 1rem;
        margin: 1.5rem 0 1rem;
    }
    .innovation-section {
        margin-left: 1.5rem;
        padding: 0.8rem;
        background: #f8f9fa;
        border-radius: 6px;
        line-height: 1.8;
        text-indent: 2em;
    }
    .innovation-section strong {
        color: #27ae60;
    }
    </style>
    """, unsafe_allow_html=True)
    
    if st.session_state.papers:
        # åœ¨å±•ç¤ºè®ºæ–‡å‰æ·»åŠ è·¯å¾„æ£€æŸ¥
        download_dir = st.session_state.analyzer.pdf_dir
        if not os.path.exists(download_dir):
            st.warning(f"ä¸‹è½½ç›®å½• {download_dir} ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»º")
            os.makedirs(download_dir)
        
        # å…ˆå±•ç¤ºåˆ†æç»“æœ
        st.header("ğŸ”¬ åˆ†æç»“æœ")
        
        # åˆ¤æ–­åˆ†æç±»å‹
        is_full_analysis = len(st.session_state.analyses) == len(st.session_state.papers)
        
        if is_full_analysis:
            # å…¨æ–‡åˆ†æï¼šå±•ç¤ºå®Œæ•´åˆ†æ
            with st.expander("ğŸ“„ è®ºæ–‡æ ¸å¿ƒè¦ç‚¹", expanded=False):
                for i, analysis in enumerate(st.session_state.analyses, 1):
                    cleaned = ArxivPaperAnalyzer._clean_thinking_chain(analysis)
                    st.markdown(f"### è®ºæ–‡ {i} åˆ†æ")
                    st.markdown(cleaned)
            
            # æ£€æŸ¥ PDF ç”Ÿæˆç»“æœ
            if st.session_state.output_files:
                pdf_path = st.session_state.output_files.get('pdf')
                md_path = st.session_state.output_files.get('markdown')
                
                # PDF ä¸‹è½½æŒ‰é’®
                if pdf_path and os.path.exists(pdf_path):
                    st.download_button(
                        label="ä¸‹è½½ PDF åˆ†ææŠ¥å‘Š",
                        data=open(pdf_path, 'rb').read(),
                        file_name=os.path.basename(pdf_path),
                        mime='application/pdf'
                    )
                else:
                    st.warning("PDF ç”Ÿæˆå¤±è´¥ï¼Œæä¾› Markdown ä¸‹è½½")
                
                # Markdown ä¸‹è½½æŒ‰é’®ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                if md_path and os.path.exists(md_path):
                    st.download_button(
                        label="ä¸‹è½½ Markdown åˆ†ææŠ¥å‘Š",
                        data=open(md_path, 'rb').read(),
                        file_name=os.path.basename(md_path),
                        mime='text/markdown'
                    )
        else:
            # æ‘˜è¦åˆ†æï¼šå±•ç¤ºäº®ç‚¹é€Ÿè§ˆ
            with st.expander("ğŸ“Š äº®ç‚¹é€Ÿè§ˆ", expanded=False):
                cleaned = ArxivPaperAnalyzer._clean_thinking_chain(st.session_state.analyses[0])
                st.markdown(cleaned)
            
            # æ£€æŸ¥ PDF ç”Ÿæˆç»“æœ
            if st.session_state.output_files:
                pdf_path = st.session_state.output_files.get('pdf')
                md_path = st.session_state.output_files.get('markdown')
                
                # PDF ä¸‹è½½æŒ‰é’®
                if pdf_path and os.path.exists(pdf_path):
                    st.download_button(
                        label="ä¸‹è½½ PDF åˆ†ææŠ¥å‘Š",
                        data=open(pdf_path, 'rb').read(),
                        file_name=os.path.basename(pdf_path),
                        mime='application/pdf'
                    )
                else:
                    st.warning("PDF ç”Ÿæˆå¤±è´¥ï¼Œæä¾› Markdown ä¸‹è½½")
                
                # Markdown ä¸‹è½½æŒ‰é’®ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                if md_path and os.path.exists(md_path):
                    st.download_button(
                        label="ä¸‹è½½ Markdown åˆ†ææŠ¥å‘Š",
                        data=open(md_path, 'rb').read(),
                        file_name=os.path.basename(md_path),
                        mime='text/markdown'
                    )
        
        # å†å±•ç¤ºè®ºæ–‡åˆ—è¡¨
        st.header("ğŸ“„ è®ºæ–‡åˆ—è¡¨")
        for i, paper in enumerate(st.session_state.papers, 1):
            print(f"è®ºæ–‡ {i} çš„é”®: {paper.keys()}")  # è°ƒè¯•æ—¥å¿—
            current_paper = paper.copy()
            
            with st.expander(f"{i}. {current_paper['title']}", expanded=False):
                st.markdown(f"**ä½œè€…**: {', '.join(current_paper['authors'])}")
                st.markdown(f"**å‘å¸ƒæ—¶é—´**: {current_paper['published']}")
                st.markdown(f"**æ‘˜è¦**: {current_paper['abstract']}")
                
                # æ–°å¢å¾®åˆ›æ–°æŒ‰é’®
                col1, col2, col3 = st.columns([1,1,3])
                with col1:
                    st.link_button("ğŸ“¥ ä¸‹è½½ PDF", current_paper['pdf_url'])
                with col2:
                    st.link_button("ğŸ”— arXiv é“¾æ¥", current_paper['arxiv_url'])
                with col3:
                    # å…¼å®¹æ—§æ•°æ®å’Œæ–°æ•°æ®
                    paper_id = current_paper.get('arxiv_id') or current_paper['arxiv_url'].split('/')[-1]
                    if st.button("âœ¨ æ·±åº¦åˆ†æ", key=f"detail_{i}"):
                        st.session_state.current_paper_id = paper_id
                        st.query_params["paper_id"] = paper_id
                        st.rerun()

def show_innovation_analysis():
    # ç‹¬ç«‹å¤´éƒ¨å¯¼èˆª
    col1, col2 = st.columns([2, 8])
    with col1:
        if st.button("â† è¿”å›è®ºæ–‡åˆ—è¡¨", use_container_width=True):
            del st.query_params["paper_id"]
            st.rerun()
    with col2:
        st.title("âœ¨ å¾®åˆ›æ–°ä¸­å¿ƒ")
    
    # é€šè¿‡IDè·å–è®ºæ–‡ï¼ˆæ”¯æŒå†å²è®°å½•ï¼‰
    paper_id = st.query_params.get("paper_id")
    if not paper_id:
        st.error("æœªæŒ‡å®šè®ºæ–‡ID")
        return
    
    # ä¼˜å…ˆä»å¾®åˆ›æ–°å­˜å‚¨è·å–
    if paper_id in st.session_state.micro_innovations:
        analysis = st.session_state.micro_innovations[paper_id]
        display_analysis(paper_id, analysis)
        return
    
    # å…¼å®¹æ—§æ•°æ®è·å–æ–¹å¼
    paper = next((p for p in st.session_state.papers if p.get('arxiv_id') == paper_id), None)
    if paper and 'micro_innovation' in paper:
        st.session_state.micro_innovations[paper_id] = paper['micro_innovation']
        display_analysis(paper_id, paper['micro_innovation'])
    else:
        st.warning("è¯¥è®ºæ–‡å°šæœªç”Ÿæˆæ·±åº¦åˆ†æ")

    print(f"å½“å‰æŸ¥è¯¢çš„paper_id: {paper_id}")
    print(f"ä¼šè¯ä¸­çš„è®ºæ–‡IDåˆ—è¡¨: {[p.get('arxiv_id') for p in st.session_state.papers]}")
    print(f"å¾®åˆ›æ–°å­˜å‚¨çš„é”®: {st.session_state.micro_innovations.keys()}")

def display_analysis(paper_id: str, analysis: str):
    """ç‹¬ç«‹å±•ç¤ºåˆ†æå†…å®¹"""
    # è·å–åŸºç¡€ä¿¡æ¯ï¼ˆå¯æ‰©å±•ä¸ºæ•°æ®åº“æŸ¥è¯¢ï¼‰
    paper = get_paper_metadata(paper_id)  # éœ€è¦å®ç°å…ƒæ•°æ®è·å–æ–¹æ³•
    
    with st.container():
        # ä¿¡æ¯å±•ç¤ºåŒº
        col_info, col_actions = st.columns([3, 1])
        with col_info:
            st.subheader(paper['title'])
            st.caption(f"ä½œè€…ï¼š{', '.join(paper['authors'])} | å‘å¸ƒæ—¶é—´ï¼š{paper['published']}")
        
        with col_actions:
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆåˆ†æ"):
                regenerate_analysis(paper_id)
            
            if st.download_button("ğŸ“¥ å¯¼å‡ºåˆ†ææŠ¥å‘Š", 
                                data=generate_report(analysis),
                                file_name=f"{paper_id}_analysis.md"):
                st.toast("å¯¼å‡ºæˆåŠŸï¼")
        
        # åˆ†æå†…å®¹å±•ç¤º
        with st.expander("ğŸ“„ åŸå§‹è®ºæ–‡æ‘˜è¦", expanded=True):
            st.write(paper['abstract'])
        
        formatted = DocumentProcessor.format_micro_innovation(analysis)
        st.markdown(f"""
            <div style="
                background: #f8f9fa;
                padding: 1.5rem;
                border-radius: 8px;
                margin-top: 1rem;
            ">
                {formatted}
            </div>
        """, unsafe_allow_html=True)

def get_paper_metadata(paper_id: str) -> Dict:
    """è·å–è®ºæ–‡å…ƒæ•°æ®ï¼ˆä»ä¼šè¯çŠ¶æ€æˆ–APIï¼‰"""
    # ä¼˜å…ˆä»ä¼šè¯çŠ¶æ€è·å–
    paper = next((p for p in st.session_state.papers if p.get('arxiv_id') == paper_id), None)
    if paper:
        return paper
    
    # å¦‚æœä¼šè¯çŠ¶æ€ä¸å­˜åœ¨ï¼Œå°è¯•é€šè¿‡ArXiv APIè·å–
    try:
        search = arxiv.Search(id_list=[paper_id])
        result = next(st.session_state.analyzer.client.results(search))
        return st.session_state.analyzer._convert_result_to_paper(result)
    except Exception as e:
        st.error(f"æ— æ³•è·å–è®ºæ–‡å…ƒæ•°æ®: {str(e)}")
        return {
            "title": "æœªçŸ¥æ ‡é¢˜",
            "authors": ["æœªçŸ¥ä½œè€…"],
            "published": "æœªçŸ¥æ—¥æœŸ",
            "abstract": "æ— æ³•è·å–æ‘˜è¦"
        }

def regenerate_analysis(paper_id: str):
    """é‡æ–°ç”Ÿæˆåˆ†æå†…å®¹"""
    with st.spinner("æ­£åœ¨é‡æ–°ç”Ÿæˆåˆ†æ..."):
        try:
            # è·å–è®ºæ–‡æ•°æ®
            paper = get_paper_metadata(paper_id)
            
            # ä¸‹è½½å¹¶å¤„ç†PDF
            pdf_path = st.session_state.analyzer.download_pdf(
                paper['pdf_url'], 
                paper['arxiv_url']
            )
            loader = PyMuPDFLoader(pdf_path)
            pages = loader.load()
            full_text = "\n".join(page.page_content for page in pages)
            
            # ç”Ÿæˆæ–°åˆ†æ
            innovation = st.session_state.analyzer.micro_innovation_chain.invoke({
                "title": paper["title"],
                "abstract": paper["abstract"],
                "full_text": full_text
            })
            
            # æ›´æ–°å­˜å‚¨
            st.session_state.micro_innovations[paper_id] = innovation['text']
            st.rerun()
            
        except Exception as e:
            st.error(f"é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}")

def generate_report(analysis: str) -> str:
    """ç”Ÿæˆå¯ä¸‹è½½çš„åˆ†ææŠ¥å‘Š"""
    # æ·»åŠ æŠ¥å‘Šå…ƒæ•°æ®
    report = f"# è®ºæ–‡åˆ›æ–°åˆ†ææŠ¥å‘Š\n\n"
    report += f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    report += "---\n\n"
    
    # æ ¼å¼åŒ–å†…å®¹
    formatted = DocumentProcessor.format_micro_innovation(analysis)
    report += formatted
    
    # è½¬æ¢ä¸ºå­—èŠ‚æµ
    return report.encode('utf-8')

def main():
    init_session_state()
    
    # æ–°å¢é¡µé¢è·¯ç”±
    if 'paper_id' in st.query_params:
        show_innovation_analysis()
        return
    
    # åŸæœ‰ä¸»é¡µé¢é€»è¾‘
    st.title("ğŸŒŸ AIæ–°çŸ¥åº“")
    
    # æ¨¡å‹é€‰æ‹©ï¼ˆç®€åŒ–åçš„ç‰ˆæœ¬ï¼‰
    model_config = sidebar_model_selection()
    
    # æœç´¢é€‰é¡¹
    search_options = sidebar_search_options()
    
    # è®ºæ–‡æœç´¢åŒºåŸŸï¼ˆç§»é™¤ provider_typeï¼‰
    search_papers(model_config["model_type"], search_options)
    
    # è®ºæ–‡å±•ç¤º
    display_papers()

if __name__ == "__main__":
    main() 