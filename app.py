import streamlit as st
# å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(
    page_title="ArXivè®ºæ–‡åˆ†æå·¥å…·",
    page_icon="ğŸ”¬",
    layout="wide"
)

import sys
import os
import webbrowser
from typing import Dict

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ Python è·¯å¾„ä¸­
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from arxiv_analyzer import ArxivPaperAnalyzer
from document_processor import AnalysisType

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'analyzer' not in st.session_state:
        # ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–
        st.session_state.analyzer = ArxivPaperAnalyzer()
    if 'papers' not in st.session_state:
        st.session_state.papers = []
    if 'analyses' not in st.session_state:
        st.session_state.analyses = []
    if 'output_files' not in st.session_state:
        st.session_state.output_files = {}

def sidebar_model_selection():
    """ä¾§è¾¹æ æ¨¡å‹é€‰æ‹©"""
    st.sidebar.header("ğŸ¤– æ¨¡å‹é€‰æ‹©")
    model_info = st.sidebar.radio(
        label="é€‰æ‹©æ¨¡å‹ç±»å‹",  
        options=["OpenAI", "DeepSeek"],
        index=0,
        horizontal=True,
        label_visibility="collapsed"
    )
    
    return {
        "model_type": "openai" if model_info == "OpenAI" else "deepseek"
    }

def load_arxiv_taxonomy():
    """åŠ è½½ArXivé¢†åŸŸåˆ†ç±»"""
    import pandas as pd
    
    try:
        df = pd.read_excel("arxiv_taxonomy_cn.xlsx")
        # æ„å»ºå±‚çº§å­—å…¸
        taxonomy = {}
        for _, row in df.iterrows():
            if row['Group'] not in taxonomy:
                taxonomy[row['Group']] = {}
            if pd.notna(row['Subgroup']):  # ç¡®ä¿Subgroupä¸æ˜¯NaN
                if row['Subgroup'] not in taxonomy[row['Group']]:
                    taxonomy[row['Group']][row['Subgroup']] = []
                taxonomy[row['Group']][row['Subgroup']].append({
                    'code': row['Code'],
                    'description': row['Description'] if pd.notna(row['Description']) else '',
                    'keywords': row['Keywords'] if pd.notna(row['Keywords']) else ''
                })
        return taxonomy
    except Exception as e:
        st.error(f"åŠ è½½é¢†åŸŸåˆ†ç±»å¤±è´¥: {str(e)}")
        return {}

def sidebar_search_options():
    """ä¾§è¾¹æ æœç´¢é€‰é¡¹"""
    st.sidebar.header("ğŸ” æœç´¢é€‰é¡¹")
    
    # é¢†åŸŸé€‰æ‹©
    field_method = st.sidebar.radio(
        "ç ”ç©¶é¢†åŸŸ",
        ["è‡ªåŠ¨æ¨è", "æ‰‹åŠ¨é€‰æ‹©"],
        index=0,
        horizontal=True
    )
    
    field = None
    if field_method == "æ‰‹åŠ¨é€‰æ‹©":
        # åŠ è½½é¢†åŸŸåˆ†ç±»
        taxonomy = load_arxiv_taxonomy()
        
        # ä¸»é¢†åŸŸé€‰æ‹©
        main_field = st.sidebar.selectbox(
            "ä¸»è¦é¢†åŸŸ",
            options=list(taxonomy.keys()),
            help="é€‰æ‹©è®ºæ–‡çš„ä¸»è¦ç ”ç©¶é¢†åŸŸ"
        )
        
        # å¦‚æœé€‰æ‹©äº†ä¸»é¢†åŸŸï¼Œæ˜¾ç¤ºå¯¹åº”çš„å­é¢†åŸŸé€‰æ‹©
        if main_field and main_field in taxonomy:
            sub_fields = list(taxonomy[main_field].keys())
            sub_field = st.sidebar.selectbox(
                "å­é¢†åŸŸ",
                options=sub_fields
            )
            if sub_field:
                field = [item['code'] for item in taxonomy[main_field][sub_field]]
    
    # å…¶ä»–æœç´¢é€‰é¡¹ï¼ˆåˆ é™¤åˆ†éš”çº¿ï¼‰
    max_papers = st.sidebar.slider(
        "è®ºæ–‡æ•°é‡",
        min_value=1,
        max_value=100,
        value=5
    )
    analysis_type = st.sidebar.radio(
        "åˆ†ææ·±åº¦", 
        ["æ‘˜è¦åˆ†æ", "å…¨æ–‡åˆ†æ"],
        index=0,
        horizontal=True
    )
    
    return {
        "field": field,
        "max_papers": max_papers,
        "analysis_type": analysis_type == "å…¨æ–‡åˆ†æ"
    }

def search_papers(model_type: str, search_options: Dict):
    """æœç´¢è®ºæ–‡"""
    st.session_state.analyzer = ArxivPaperAnalyzer(
        model_type=model_type
    )
    
    with st.spinner("æ­£åœ¨æœç´¢å’Œåˆ†æè®ºæ–‡..."):
        query = st.text_input(
            label="è®ºæ–‡æœç´¢",
            placeholder="è¾“å…¥ç ”ç©¶ä¸»é¢˜ï¼Œå¦‚ï¼šæœºå™¨å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†",
            label_visibility="collapsed"
        )
        
        if st.button("å¼€å§‹æœç´¢"):
            try:
                results = st.session_state.analyzer.search_and_analyze_papers(
                    query=query,
                    max_papers=search_options['max_papers'],
                    analyze_full_text=search_options['analysis_type'],
                    field=search_options['field']
                )
                
                st.session_state.papers = results.get('papers', [])
                st.session_state.analyses = results.get('analyses', [])
                st.session_state.output_files = results.get('outputs', {})
                
                st.success(f"æˆåŠŸè·å– {len(st.session_state.papers)} ç¯‡è®ºæ–‡")
            except Exception as e:
                st.error(f"æœç´¢å¤±è´¥: {str(e)}")

def display_papers():
    """å±•ç¤ºè®ºæ–‡å’Œåˆ†æç»“æœ"""
    if st.session_state.papers:
        # å…ˆå±•ç¤ºåˆ†æç»“æœ
        st.header("ğŸ”¬ åˆ†æç»“æœ")
        
        # åˆ¤æ–­åˆ†æç±»å‹
        is_full_analysis = len(st.session_state.analyses) == len(st.session_state.papers)
        
        if is_full_analysis:
            # å…¨æ–‡åˆ†æï¼šå±•ç¤ºæ¯ç¯‡è®ºæ–‡çš„æ ¸å¿ƒè¦ç‚¹
            st.subheader("ğŸ“‹ è®ºæ–‡æ ¸å¿ƒè¦ç‚¹")
            for i, (paper, analysis) in enumerate(zip(st.session_state.papers, st.session_state.analyses), 1):
                with st.expander(f"è®ºæ–‡ {i}: {paper['title']} - æ ¸å¿ƒè¦ç‚¹", expanded=True):
                    core_points = extract_core_points(analysis)
                    st.markdown(core_points)
            
            # æ£€æŸ¥ PDF ç”Ÿæˆç»“æœ
            if st.session_state.output_files:
                pdf_path = st.session_state.output_files.get('pdf')
                md_path = st.session_state.output_files.get('markdown')
                
                # PDF ä¸‹è½½æŒ‰é’®
                if pdf_path and os.path.exists(pdf_path):
                    st.download_button(
                        label="ä¸‹è½½ PDF åˆ†ææŠ¥å‘Š",
                        data=open(pdf_path, 'rb').read(),
                        file_name=os.path.basename(pdf_path),
                        mime='application/pdf'
                    )
                else:
                    st.warning("PDF ç”Ÿæˆå¤±è´¥ï¼Œæä¾› Markdown ä¸‹è½½")
                
                # Markdown ä¸‹è½½æŒ‰é’®ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                if md_path and os.path.exists(md_path):
                    st.download_button(
                        label="ä¸‹è½½ Markdown åˆ†ææŠ¥å‘Š",
                        data=open(md_path, 'rb').read(),
                        file_name=os.path.basename(md_path),
                        mime='text/markdown'
                    )
        else:
            # æ‘˜è¦åˆ†æï¼šå±•ç¤ºäº®ç‚¹é€Ÿè§ˆ
            with st.expander("ğŸ“Š äº®ç‚¹é€Ÿè§ˆ", expanded=True):
                cleaned = ArxivPaperAnalyzer._clean_thinking_chain(st.session_state.analyses[0])
                st.markdown(cleaned)
            
            # æ£€æŸ¥ PDF ç”Ÿæˆç»“æœ
            if st.session_state.output_files:
                pdf_path = st.session_state.output_files.get('pdf')
                md_path = st.session_state.output_files.get('markdown')
                
                # PDF ä¸‹è½½æŒ‰é’®
                if pdf_path and os.path.exists(pdf_path):
                    st.download_button(
                        label="ä¸‹è½½ PDF åˆ†ææŠ¥å‘Š",
                        data=open(pdf_path, 'rb').read(),
                        file_name=os.path.basename(pdf_path),
                        mime='application/pdf'
                    )
                else:
                    st.warning("PDF ç”Ÿæˆå¤±è´¥ï¼Œæä¾› Markdown ä¸‹è½½")
                
                # Markdown ä¸‹è½½æŒ‰é’®ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                if md_path and os.path.exists(md_path):
                    st.download_button(
                        label="ä¸‹è½½ Markdown åˆ†ææŠ¥å‘Š",
                        data=open(md_path, 'rb').read(),
                        file_name=os.path.basename(md_path),
                        mime='text/markdown'
                    )
        
        # å†å±•ç¤ºè®ºæ–‡åˆ—è¡¨
        st.header("ğŸ“„ è®ºæ–‡åˆ—è¡¨")
        for i, paper in enumerate(st.session_state.papers, 1):
            with st.expander(f"{i}. {paper['title']}", expanded=False):
                st.markdown(f"**ä½œè€…**: {', '.join(paper['authors'])}")
                st.markdown(f"**å‘å¸ƒæ—¶é—´**: {paper['published']}")
                st.markdown(f"**æ‘˜è¦**: {paper['abstract']}")
                
                # æ·»åŠ ä¸‹è½½å’Œé“¾æ¥æŒ‰é’®
                col1, col2 = st.columns(2)
                with col1:
                    st.link_button("ğŸ“¥ ä¸‹è½½ PDF", paper['pdf_url'])
                with col2:
                    st.link_button("ğŸ”— arXiv é“¾æ¥", paper['arxiv_url'])

def extract_core_points(analysis: str) -> str:
    """ä»å®Œæ•´åˆ†æä¸­æå–æ ¸å¿ƒè¦ç‚¹"""
    try:
        # å®šä¹‰å¯èƒ½çš„æ ¸å¿ƒè¦ç‚¹æ ‡é¢˜
        sections = [
            "## ğŸ¯ æ ¸å¿ƒè¦ç‚¹é€Ÿè§ˆ", 
            "## æ ¸å¿ƒè¦ç‚¹é€Ÿè§ˆ", 
            "## ğŸ¯ æ ¸å¿ƒè¦ç‚¹", 
            "## æ ¸å¿ƒè¦ç‚¹"
        ]
        
        # å°è¯•æ‰¾åˆ°æ ¸å¿ƒè¦ç‚¹éƒ¨åˆ†
        for section in sections:
            if section in analysis:
                # æ‰¾åˆ°è¯¥éƒ¨åˆ†åï¼Œæå–åˆ°ä¸‹ä¸€ä¸ªäºŒçº§æ ‡é¢˜ä¹‹å‰çš„å†…å®¹
                start_index = analysis.index(section) + len(section)
                next_section_match = analysis.find("## ", start_index)
                
                if next_section_match != -1:
                    core_points = analysis[start_index:next_section_match].strip()
                else:
                    core_points = analysis[start_index:].strip()
                
                # å¦‚æœæå–çš„å†…å®¹å¤ªçŸ­ï¼Œè¿”å›æ•´ä¸ªåˆ†æ
                if len(core_points) > 50:
                    return core_points
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šéƒ¨åˆ†ï¼Œå°è¯•æå–å‰500ä¸ªå­—ç¬¦
        return analysis[:500] + "..."
    
    except Exception as e:
        print(f"æå–æ ¸å¿ƒè¦ç‚¹å‡ºé”™: {str(e)}")
        return "æ— æ³•æå–æ ¸å¿ƒè¦ç‚¹"

def main():
    init_session_state()
    
    st.title("ğŸŒŸ ArXiv è®ºæ–‡æ™ºèƒ½åˆ†æå¹³å°")
    
    # æ¨¡å‹é€‰æ‹©ï¼ˆç®€åŒ–åçš„ç‰ˆæœ¬ï¼‰
    model_config = sidebar_model_selection()
    
    # æœç´¢é€‰é¡¹
    search_options = sidebar_search_options()
    
    # è®ºæ–‡æœç´¢åŒºåŸŸï¼ˆç§»é™¤ provider_typeï¼‰
    search_papers(model_config["model_type"], search_options)
    
    # è®ºæ–‡å±•ç¤º
    display_papers()

if __name__ == "__main__":
    main() 